{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b11254d1a270988e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Required Assignment 18.3: Bag of Words and TF–IDF\n",
    "\n",
    "**Expected Time = 60 minutes**\n",
    "\n",
    "**Total Points = 35**\n",
    "\n",
    " In this activity you will use the Scikit-Learn vectorization tools `CountVectorizer` and  `TfidfVectorizer`  to create a numerical  representation of text in a DataFrame.  You will explore how different parameter settings affect the performance of a `LogisticRegression` estimator on a binary classification problem to see if the performance on predicting the WhatsApp status improves with a different representation.\n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n",
    "- [Problem 4](#-Problem-4)\n",
    "- [Problem 5](#-Problem-5)\n",
    "- [Problem 6](#-Problem-6)\n",
    "- [Problem 7](#-Problem-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-580b2c525505e59a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### The Data\n",
    "\n",
    "The cell below uses the \"sad\" and \"happy\" sentiments datasets from Kaggle to form the target of our classification models.  The data is also split and named appropriately below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_df = pd.read_csv('data/Emotion(happy).csv')\n",
    "sad_df = pd.read_csv('data/Emotion(sad).csv.zip', compression = 'zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([happy_df, sad_df]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full_df.drop('sentiment', axis = 1)\n",
    "y = full_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X['content'], y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1af9c3aaf69f904f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Using the `CountVectorizer`\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "To create a bag of words representation of your text data, below create an instance of the `CountVectorizer` with default settings as `cvect`. \n",
    "\n",
    "Next, use the `fit_transform` function on `cvect` to transform the training data `X_train` and assign the transformed version of the text to `dtm`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-993194297edf95fd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "cvect = ''\n",
    "dtm = ''\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "cvect = CountVectorizer()\n",
    "dtm = cvect.fit_transform(X_train)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "pd.DataFrame(dtm.toarray(), columns = cvect.get_feature_names_out()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-748f6d75238662a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Problem 2\n",
    "\n",
    "#### Limiting words with the `CountVectorizer`\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "Now, to remove stopwords from the text before vectorizing create a new instance of the `CountVectorizer` with argument `stop_words = 'english'`. Assign this to the variable `cvect2`.\n",
    "\n",
    "Next, use the `fit_transform` function on `cvect2` to transform the training data `X_train` and assign the transformed version of the text to `X_train_vect_2`.  \n",
    "\n",
    "Finally, transform the test data `X_test` as `X_test_vect_2` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3774a2265d6e5e27",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "cvect2 = ''\n",
    "X_train_vect_2 = ''\n",
    "X_test_vect_2 = ''\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "cvect2 = CountVectorizer(stop_words = 'english')\n",
    "X_train_vect_2 = cvect2.fit_transform(X_train)\n",
    "X_test_vect_2 = cvect2.transform(X_test)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "X_train_vect_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-52dbe3ec03ade066",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Using the text with `LogisticRegression`\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "Create a `Pipeline` object named `vect_pipe_1` below that has steps named `cvect` and `lgr`, using both a default `CountVectorizer` transformer and `LogisticRegression` estimator. \n",
    "\n",
    "Fit this pipeline on the training data `X_train` and `y_train`.\n",
    "\n",
    "Finally, use the function `score` to evaluate it on the test set `X_test` and `y_test`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0ced72c8a300928f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "vect_pipe_1 = ''\n",
    "\n",
    "test_acc = ''\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "vect_pipe_1 = Pipeline([('cvect', CountVectorizer()),\n",
    "                       ('lgr', LogisticRegression())])\n",
    "vect_pipe_1.fit(X_train, y_train)\n",
    "test_acc = vect_pipe_1.score(X_test, y_test)\n",
    "### END SOLUTION\n",
    "\n",
    "\n",
    "### ANSWER CHECK\n",
    "vect_pipe_1.named_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-67c7fd85b923ac68",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "#### Pipeline and Grid Search\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "Initialize a `GridSearchCV` object with the pipeline `vect_pipe_1` and parameter grid `params` given below. Assign this result to the variable `grid`.\n",
    "\n",
    "Fit the `grid` object on training data `X_train` and `y_train`.\n",
    "\n",
    "Finaly, use the function `score` to evaluate it on the test set `X_test` and `y_test`. Assign the result to `test_acc`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'cvect__max_features': [100, 500, 1000, 2000],\n",
    "         'cvect__stop_words': ['english', None]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e57872e309a8659f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "grid = ''\n",
    "test_acc = ''\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "grid = GridSearchCV(vect_pipe_1, param_grid=params)\n",
    "grid.fit(X_train, y_train)\n",
    "test_acc = grid.score(X_test, y_test)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-19a9e26f3d0c4105",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "\n",
    "### Problem 5\n",
    "\n",
    "#### Using `TfidfVectorizer` in a `Pipeline`\n",
    "\n",
    "**5 Points** \n",
    "\n",
    "Now, you are to use the Scikit-Learn transformer `TfidfVectorizer` to transform the WhatsApp data from Kaggle.  The data is loaded and split below. \n",
    "\n",
    "Initialize a `TfidfVectorizer` object with default parameters and assign it to the variable `tfidif`. \n",
    "\n",
    "Next, use the function `fit_transform` with argument equal to `X_train` on `tfidf`. Assign this result to the variable `dtm`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-137ed937ed2a5686",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "tfidf = ''\n",
    "dtm = ''\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "tfidf = TfidfVectorizer()\n",
    "dtm = tfidf.fit_transform(X_train)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "pd.DataFrame(dtm.toarray(), columns = tfidf.get_feature_names_out()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e88662bb3385002a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "\n",
    "### Problem 6\n",
    "\n",
    "#### Pipeline with `TfidfVectorizer`\n",
    "\n",
    "*5 Points** \n",
    "\n",
    "Below, create a pipeline named `tfidf_pipe` with steps `tfidf` and `lgr` given by a `TfidfVectorizer` and a `LogisticRegression` estimators, respectively. \n",
    "\n",
    "Next, use the function `fit` on `tfidf_pipe` to fit the training data `X_train` and `y_train`.\n",
    "\n",
    "Finally, use the function `score` on `tfidf_pipe` to compute the score on the test data `X_test` and `y_test`. Assign the result to `test_acc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4f4ab63ae87387c5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "tfidf_pipe = ''\n",
    "\n",
    "test_acc = ''\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "tfidf_pipe = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                       ('lgr', LogisticRegression())])\n",
    "tfidf_pipe.fit(X_train, y_train)\n",
    "test_acc = tfidf_pipe.score(X_test, y_test)\n",
    "### END SOLUTION\n",
    "\n",
    "\n",
    "### ANSWER CHECK\n",
    "tfidf_pipe.named_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-327d300d8627767b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "\n",
    "### Problem 7\n",
    "\n",
    "#### Grid Searching the Pipeline\n",
    "\n",
    "**5 Points** \n",
    "\n",
    "Initialize a `GridSearchCV` object with the pipeline `tfidf_pipe` and parameter grid `params` given below. Assign this result to the variable `grid`.\n",
    "\n",
    "Fit the `grid` object on training data `X_train` and `y_train`.\n",
    "\n",
    "Finaly, use the function `score` to evaluate it on the test set `X_test` and `y_test`. Assign the result to `test_acc`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4b850885a5ae76e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "params = {'tfidf__max_features': [100, 500, 1000, 2000],\n",
    "         'tfidf__stop_words': ['english', None]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1662e7e231fdd32a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "grid = ''\n",
    "test_acc = ''\n",
    "\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "grid = GridSearchCV(tfidf_pipe, param_grid=params)\n",
    "grid.fit(X_train, y_train)\n",
    "test_acc = grid.score(X_test, y_test)\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
