{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-caf9b09bbb7a6d2b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Required Assignment 12.1: Identifying the Best K\n",
    "\n",
    "This activity focuses on identifying the \"best\" number of neighbors that optimize the accuracy of a `KNearestNeighbors` estimator. The ideal number of neighbors will be selected through cross-validation and a grid search over the `n_neighbors` parameter.  Again, before building the model, you will want to scale the data in a `Pipeline`.\n",
    "\n",
    "**Expected Time: 60 Minutes**\n",
    "\n",
    "**Total Points: 50**\n",
    "\n",
    "#### Index\n",
    "\n",
    "- [Problem 1](#Problem-1)\n",
    "- [Problem 2](#Problem-2)\n",
    "- [Problem 3](#Problem-3)\n",
    "- [Problem 4](#Problem-4)\n",
    "- [Problem 5](#Problem-5)\n",
    "- [Problem 6](#Problem-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-92956d10bb3cb667",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### The Dataset\n",
    "\n",
    "Again, you will use the credit default dataset to predict default -- yes or no.  The data is loaded and split into train and test sets for you below.  You will again build a column transformer to encode the `student` feature.  Note that scikit-learn handles a string target features in the `KNeighborsClassifier`, and we do not need to encode this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/default.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('default', axis = 1), \n",
    "                                                    df['default'],\n",
    "                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f7072b73c70cd968",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Baseline for Models\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "Before starting the modeling process, you should have a baseline to determine whether your model is any good. \n",
    "\n",
    "Consider the `default` column of `df`. Perform a `value_counts` operation with the argument `normalize` equal to `True`. \n",
    "\n",
    "What would the accuracy of such a classifier be?  Enter your answer as a float to `baseline` below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c176ee67477c55e6",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "baseline = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "baseline = df['default'].value_counts(normalize = True).iloc[0]\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1dd40c4b785568a5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Column transforms and KNN\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Use the `make_column_transformer` to create a column `transformer`. Inside the `make_column_transformer` specify an instance of the `OneHotEncoder` transformer from scikit-learn. Inside `OneHotEncoder` set `drop` equal to `'if_binary'`. Apply this transformation to the `student` column. On the `remainder` columns, apply a `StandardScaler()` transformation.\n",
    " \n",
    "\n",
    "Next, build a `Pipeline` named `knn_pipe` with  steps `transform` and `knn`. Set `transform` equal to `transformer` and `knn` equal to `KNeighborsClassifier()`. Be sure to leave all the settings in `knn` as the default.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ec78a85ab645b292",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "transformer = ''\n",
    "knn_pipe = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "transformer = make_column_transformer((OneHotEncoder(drop = 'if_binary'), ['student']),\n",
    "                                     remainder = StandardScaler())\n",
    "knn_pipe = Pipeline([('transform', transformer), ('knn', KNeighborsClassifier())])\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "knn_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6401f33e5bcd4eed",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Parameter grid\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Now that your pipeline is ready, you are to construct a parameter grid to search over.  Consider two things:\n",
    "\n",
    "- You will not be able to predict on a test dataset where `n_neigbors > len(test_data)`.  This will limit our upper bound on `k`.  In this example, too high a `k` will slow down the computation, so only consider `k = [1, 3, 5, ..., 21]`. \n",
    "- Ties in voting are decided somewhat arbitrarily and for speed and clarity you should consider only odd values for the number of neighbors\n",
    "\n",
    "Creating a dictionary called `params` that specifies hyperparameters for the KNN classifier. \n",
    "\n",
    "- The key of your dictionary will be `knn__n_neighbors`\n",
    "- The values in your dictionary will be `list(range(1, 22, 2))`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-49c0659213e1b9b6",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "params = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "params = {'knn__n_neighbors': list(range(1, 22, 2))}\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "list(params.values())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1c309eac303dc895",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 4\n",
    "\n",
    "#### Grid search `k`\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "- Use `GridSearchCV` with the `knn_pipe` and `param_grid` equal to `params`. Assign the result to `knn_grid`.\n",
    "- Use the `fit` function on `knn_grid` to train your model on `X_train` and `y_train`.\n",
    "- Retrieve the best value for the hyperparameter `k` from the `best_params_` attribute of the grid search object `knn_grid`. Assign the result to `best_k`.\n",
    "- Use the `score` function to calculate the accuracy of the `knn_grid` classifier on a test dataset. Assign your best models accuracy on the test data as a float to `best_acc`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2cd786c8b30044e8",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "knn_grid = ''\n",
    "best_k = ''\n",
    "best_acc = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "params = {'knn__n_neighbors': list(range(1, 22, 2))}\n",
    "knn_grid = GridSearchCV(knn_pipe, param_grid=params)\n",
    "knn_grid.fit(X_train, y_train)\n",
    "best_k = list(knn_grid.best_params_.values())[0]\n",
    "best_acc = knn_grid.score(X_test, y_test)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(best_acc)\n",
    "print(best_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-915465698b91be8b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 5\n",
    "\n",
    "#### Other parameters to consider\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "The number of neighbors is not the only parameter in the implementation from scikit-learn.  For example, you can also consider different weightings of points based on their distance, change the distance metric, and search over alternative versions of certain metrics like Minkowski.  See the docstring from `KNeighborsClassifier` below. \n",
    "\n",
    "```\n",
    "weights : {'uniform', 'distance'} or callable, default='uniform'\n",
    "    Weight function used in prediction.  Possible values:\n",
    "\n",
    "    - 'uniform' : uniform weights.  All points in each neighborhood\n",
    "      are weighted equally.\n",
    "    - 'distance' : weight points by the inverse of their distance.\n",
    "      in this case, closer neighbors of a query point will have a\n",
    "      greater influence than neighbors which are further away.\n",
    "    - [callable] : a user-defined function which accepts an\n",
    "      array of distances, and returns an array of the same shape\n",
    "      containing the weights.\n",
    "      \n",
    "===========================\n",
    "\n",
    "p : int, default=2\n",
    "    Power parameter for the Minkowski metric. When p = 1, this is\n",
    "    equivalent to using manhattan_distance (l1), and euclidean_distance\n",
    "    (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
    "    \n",
    "```\n",
    "\n",
    "Create a new parameter grid and consider both weightings as well as `p = [1, 2]`.  Assign this as a dictionary to `params2` below.  \n",
    "\n",
    "Search over these parameters in your `knn_pipe` with a `GridSearchCV` named `weight_grid` below. Also, consider `n_neighbors` as in [Problem 4](#-Problem-4).  Did your new grid search results perform better than earlier?  Assign this grid's accuracy to `weights_acc` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a28b8c5d58df2812",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "params2 = ''\n",
    "weight_grid = ''\n",
    "weights_acc = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "params2 = {'knn__n_neighbors': list(range(1, 22, 2)),\n",
    "          'knn__weights': ['uniform', 'distance'],\n",
    "          'knn__p': [1, 2]}\n",
    "weight_grid = GridSearchCV(knn_pipe, param_grid=params2)\n",
    "weight_grid.fit(X_train, y_train)\n",
    "weights_acc = weight_grid.score(X_test, y_test)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(weights_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f9041e2db48f6fef",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 6\n",
    "\n",
    "#### Further considerations\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "When performing your grid search you want to also be sensitive to the amount of parameters you are searching and the number of different models being built.  How many models were constructed in [Problem 5](#-Problem-5)?  Enter your answer as an integer to `ans6` below.  You might use the grids `.cv_results_` attribute to determine this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-08e9caf7dd03bc11",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "\n",
    "ans6 = ''\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "ans6 = int(44*5)\n",
    "### END SOLUTION\n",
    "\n",
    "# Answer check\n",
    "print(ans6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
