{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dfb3b6e3696eff65",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Required Assignment 15.3: Stochastic Gradient Descent\n",
    "\n",
    "**Expected Time = 30 minutes**\n",
    "\n",
    "**Total Points = 20**\n",
    "\n",
    "This activity explores the use of the `SGDRegressor` from scikitlearn.  While there is not a standard gradient descent estimator, the more efficient example of stochastic gradient descent is available.  You will use the earlier credit dataset to explore its use and learn an important lesson about scaling your data with gradient descent methods. \n",
    "\n",
    "#### Index\n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit = pd.read_csv('data/Credit.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = credit[['Income', 'Limit']]\n",
    "y = credit['Balance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4c65193ba8d1cc68",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Fitting a basic Linear Regression model\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "To begin, use the `LinearRegression` estimator with all default parameters to build a model. Fit this model  on the training data `X_train` and `y_train`. Assign this model to the variable `lr`.\n",
    "\n",
    "Next, assign the training and testing errors to `train_mse` and `test_mse` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-070c21d90d3625e3",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "lr = ''\n",
    "train_mse = ''\n",
    "test_mse = ''\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "train_mse = mean_squared_error(y_train, lr.predict(X_train))\n",
    "test_mse = mean_squared_error(y_test, lr.predict(X_test))\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(train_mse)\n",
    "print(test_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e7f119dc798009c7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Fitting a basic SGD model\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Define define an `SGDRegressor` estimator with `random_state = 42` and fit to the training data `X_train` and `y_train`. Assign this model to `sgd_defaults`.\n",
    "\n",
    "Next, assign the training and testing errors to `train_mse` and `test_mse` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-76a36ca97a2b71c5",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "sgd_defaults = ''\n",
    "train_mse = ''\n",
    "test_mse = ''\n",
    "    \n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "sgd_defaults = SGDRegressor(random_state=42).fit(X_train, y_train)\n",
    "train_mse = mean_squared_error(y_train, sgd_defaults.predict(X_train))\n",
    "test_mse = mean_squared_error(y_test, sgd_defaults.predict(X_test))\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(sgd_defaults)\n",
    "print(train_mse)\n",
    "print(test_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ffede5ecd7c59430",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Scaling the Data\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "An important message in gradient descent methods is that scaling the data and using regularization helps to constrain the solution path.  \n",
    "\n",
    "You should be able to see the effect of providing the `SGDRegressor` scaled data below.  \n",
    "\n",
    "Define define an `SGDRegressor` estimator with `random_state = 42` and fit to the training data `X_tr_scaled` and `y_train`. Assign this model to `sgd_scaled`.\n",
    "\n",
    "Next, assign the training and testing errors to `train_mse` and `test_mse` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_tr_scaled = scaler.fit_transform(X_train)\n",
    "X_ts_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a791ed8b60cf0a08",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "sgd_scaled = ''\n",
    "    \n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "sgd_scaled = SGDRegressor(random_state = 42).fit(X_tr_scaled, y_train)\n",
    "train_mse = mean_squared_error(y_train, sgd_scaled.predict(X_tr_scaled))\n",
    "test_mse = mean_squared_error(y_test, sgd_scaled.predict(X_ts_scaled))\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(sgd_scaled)\n",
    "print(train_mse)\n",
    "print(test_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can return to your earlier examples and see if scaling your data made any differences in the gradient descent convergence, this is important to all models using a gradient descent method and you will see this again with neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
