{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ec08a2e455a16e1e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Required Assignment 16.1: Maximum Margin Classifier\n",
    "\n",
    "**Expected Time = 30 minutes** \n",
    "\n",
    "**Total Points = 25** \n",
    "\n",
    "This activity focuses on basic maximum margin classifiers with the help of Scikit-Learn's `SVC` estimator.  Soon, you will dive deeper into the mechanics of the Support Vector Classifier.  To get started, you will use this as many other estimators and visualize the margins for the resulting classifier.  Specifically, we will examine the **support vectors** and see how we can use `SVC` to visualize boundaries for the maximum margin classifier.\n",
    "\n",
    "#### Index\n",
    "\n",
    "- [Problem 1](#-Problem-1)\n",
    "- [Problem 2](#-Problem-2)\n",
    "- [Problem 3](#-Problem-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-61eea22818ed98d9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### The Data\n",
    "\n",
    "You will use the same synthetic data from the previous assignment and compare how the maximum margin classifier resulting from `SVC` looks under basic settings.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(cluster_std=2.0, centers = 2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for label, color in enumerate(['blue', 'orange']):\n",
    "    ax.scatter(X_train[y_train == label][:, 0], X_train[y_train == label][:, 1], c=color, label=label,\n",
    "               alpha=0.6, edgecolors='black', s = 60)\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], c='green', label='test',\n",
    "               alpha=0.8, edgecolors='black', s = 70)\n",
    "    \n",
    "ax.legend(title = 'Class')\n",
    "ax.set_title('Synthetic Binary Classification Dataset')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-27b6ef5b343f9702",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "#### Fitting the `SVC`\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "Instantiate the `SVC` estimator with a linear decision boundary `kernel = 'linear'` and fit it to your training data `X_train` and `y_train`. Assign this to the variable `svc_1` below. \n",
    "\n",
    "\n",
    "Next, examine the **support vectors** with the `.support_vectors_` attribute on `svc_1`, and assign this as a numpy array to `support_vectors`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a1106ba8c91012fc",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "svc_1 = ''\n",
    "support_vectors = ''\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "svc_1 = SVC(kernel = 'linear').fit(X_train, y_train)\n",
    "support_vectors = svc_1.support_vectors_\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "support_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment to visualize\n",
    "fig, ax = plt.subplots()\n",
    "for label, color in enumerate(['blue', 'orange']):\n",
    "    ax.scatter(X[y == label][:, 0], X[y == label][:, 1], c=color, \n",
    "               alpha=0.8, edgecolors='none')\n",
    "ax.set_title('Support Vectors And Margin')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.scatter(support_vectors[:, 0], support_vectors[:, 1], color = 'red', s = 80, marker = 'x', label = 'Support Vectors Through Here')\n",
    "ax.grid(True)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-394de0f8004a1861",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "#### Examining the resulting Margin\n",
    "\n",
    "**10 Points**\n",
    "\n",
    "As seen above, the results of the fit `SVC` contain points through which the **support vectors** pass.  \n",
    "\n",
    "\n",
    "The points that determine this maximum margin pass through the support vectors.  Because these vectors are parallel to one another they share a slope.  \n",
    "\n",
    "Using the `support_vectors` determine the slope of these lines and assign this to `slope2` below.  This will complete the functions `lower` and `upper` that determine a line between the two lower points for the support vectors and the one upper point. \n",
    "\n",
    "\n",
    "Uncomment the code to visualize your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b10615739eee2ff5",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "slope2 = ''\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "slope2 = (support_vectors[1, 1] - support_vectors[2, 1])/(support_vectors[1, 0] - support_vectors[2, 0]) \n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "def lower(x):\n",
    "    return slope2*(x - support_vectors[2, 0]) + support_vectors[2, 1]\n",
    "def upper(x):\n",
    "    return slope2*(x - support_vectors[0, 0]) + support_vectors[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(X, lower(X), '--r')\n",
    "# plt.plot(X, upper(X), '--r')\n",
    "# plt.scatter(X_train[:, 0], X_train[:, 1], c = y_train)\n",
    "# plt.scatter(support_vectors[:, 0], support_vectors[:, 1], alpha = 0.6,color = 'red', s = 80, edgecolor = 'black')\n",
    "# plt.title('Support Vectors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-760f2a0af774d87e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "[Back to top](#-Index)\n",
    "\n",
    "### Problem 3\n",
    "\n",
    "#### Using the `decision_function` approach\n",
    "\n",
    "**5 Points**\n",
    "\n",
    "Similar to what you found using the slope of the line through the **support vectors**, the fit estimator can return information on these boundaries directly using the `.decision_function`.  Below, the `decision_function` is used to generate a contour plot of the support vectors and their midpoint.  The test data are plotted against the training data and support vectors.  \n",
    "\n",
    "Based on this visualization did the Maximum Margin classifier misclassify any points? Note that the black line between the red support vectors is the decision boundary. Assign your answer as a boolean to `ans3` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid of points to plot decision boundaries \n",
    "XX, YY = np.meshgrid(X_train[:, 0], X_train[:, 1])\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "#Output from grid of points based on decision function\n",
    "Z = svc_1.decision_function(xy).reshape(XX.shape)\n",
    "#Plots of points and support vectors\n",
    "fig, ax = plt.subplots()\n",
    "ax.contour(XX, YY,  Z, levels = [0], colors = ['black'])\n",
    "ax.scatter(X_train[:, 0], X_train[:, 1], alpha = 0.3, label = 'Train Data')\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], s = 100, alpha = 0.5, edgecolor = 'black', label = 'Test Data')\n",
    "ax.scatter(support_vectors[:, 0], support_vectors[:, 1], color = 'red', s = 80, marker = 'x')\n",
    "ax.legend(loc = 'upper left')\n",
    "ax.set_title('Support Vectors and Maximum Margin\\nNote Black Line as Decision Boundary');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5a83dd029dfe25dd",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "ans3 = '' #misclassified points -- True is yes/ False is no\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "ans3 = False\n",
    "### END SOLUTION\n",
    "\n",
    "### ANSWER CHECK\n",
    "print(ans3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e9dd0affa70802fc",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Comparing Other Boundaries\n",
    "\n",
    "Below, plotting both a `LogisticRegression` and a Quadratic boundary for a maximum margin classifier are shown.  Note how similar the linear `SVC` and `LogisticRegression` estimators are, while the quadratic boundary seems to be less effective than a linear boundary.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr = LogisticRegression().fit(X_train, y_train)\n",
    "Z2 = lgr.decision_function(xy).reshape(XX.shape)\n",
    "plt.contour(XX, YY,  Z2, levels = [0], colors = ['red'])\n",
    "plt.contour(XX, YY,  Z, levels = [0], colors = ['black'])\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c = y_train)\n",
    "plt.scatter(support_vectors[:, 0], support_vectors[:, 1], color = 'red', s = 80, marker = 'x')\n",
    "plt.title('Logistic Regression (red) vs. Linear SVC (black)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc2 = SVC(kernel='poly').fit(X_train, y_train)\n",
    "h = 0.1\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "Z3 = svc2.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "plt.contourf(xx, yy,  Z3, cmap = 'YlGn', alpha = 0.4)\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c = 'grey', label = 'Train')\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c = 'black', label = 'Test')\n",
    "plt.legend()\n",
    "plt.title('Quadratic Boundary from SVC');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
